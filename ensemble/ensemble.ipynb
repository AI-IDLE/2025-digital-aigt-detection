{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk9pzsoodqaG"
      },
      "source": [
        "**meta_train.csv 생성**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXP7QIduO56p"
      },
      "source": [
        "1. 라이브러리 임포트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\2025digital\\2025-digital-aigt-detection\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu124\n",
            "Requirement already satisfied: torch==2.6.0+cu124 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from -r ./requirements.txt (line 1)) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers==4.53.2 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from -r ./requirements.txt (line 2)) (4.53.2)\n",
            "Requirement already satisfied: datasets==4.0.0 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from -r ./requirements.txt (line 3)) (4.0.0)\n",
            "Requirement already satisfied: peft==0.16.0 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from -r ./requirements.txt (line 4)) (0.16.0)\n",
            "Requirement already satisfied: accelerate==1.8.1 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from -r ./requirements.txt (line 5)) (1.8.1)\n",
            "Requirement already satisfied: bitsandbytes==0.46.1 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from -r ./requirements.txt (line 6)) (0.46.1)\n",
            "Requirement already satisfied: fsspec==2025.3.0 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from -r ./requirements.txt (line 7)) (2025.3.0)\n",
            "Requirement already satisfied: numpy==2.0.2 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from -r ./requirements.txt (line 8)) (2.0.2)\n",
            "Requirement already satisfied: pandas==2.2.2 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from -r ./requirements.txt (line 9)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn==1.6.1 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from -r ./requirements.txt (line 10)) (1.6.1)\n",
            "Requirement already satisfied: scipy==1.15.3 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from -r ./requirements.txt (line 11)) (1.15.3)\n",
            "Requirement already satisfied: tqdm==4.67.1 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from -r ./requirements.txt (line 12)) (4.67.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from torch==2.6.0+cu124->-r ./requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from torch==2.6.0+cu124->-r ./requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from torch==2.6.0+cu124->-r ./requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from torch==2.6.0+cu124->-r ./requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from torch==2.6.0+cu124->-r ./requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from transformers==4.53.2->-r ./requirements.txt (line 2)) (0.33.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from transformers==4.53.2->-r ./requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from transformers==4.53.2->-r ./requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from transformers==4.53.2->-r ./requirements.txt (line 2)) (2024.11.6)\n",
            "Requirement already satisfied: requests in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from transformers==4.53.2->-r ./requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from transformers==4.53.2->-r ./requirements.txt (line 2)) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from transformers==4.53.2->-r ./requirements.txt (line 2)) (0.5.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from datasets==4.0.0->-r ./requirements.txt (line 3)) (21.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from datasets==4.0.0->-r ./requirements.txt (line 3)) (0.3.8)\n",
            "Requirement already satisfied: xxhash in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from datasets==4.0.0->-r ./requirements.txt (line 3)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from datasets==4.0.0->-r ./requirements.txt (line 3)) (0.70.16)\n",
            "Requirement already satisfied: psutil in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from peft==0.16.0->-r ./requirements.txt (line 4)) (5.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from pandas==2.2.2->-r ./requirements.txt (line 9)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from pandas==2.2.2->-r ./requirements.txt (line 9)) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from pandas==2.2.2->-r ./requirements.txt (line 9)) (2023.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from scikit-learn==1.6.1->-r ./requirements.txt (line 10)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from scikit-learn==1.6.1->-r ./requirements.txt (line 10)) (3.6.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from tqdm==4.67.1->-r ./requirements.txt (line 12)) (0.4.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from sympy==1.13.1->torch==2.6.0+cu124->-r ./requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0->-r ./requirements.txt (line 3)) (3.12.14)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from python-dateutil>=2.8.2->pandas==2.2.2->-r ./requirements.txt (line 9)) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from requests->transformers==4.53.2->-r ./requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from requests->transformers==4.53.2->-r ./requirements.txt (line 2)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from requests->transformers==4.53.2->-r ./requirements.txt (line 2)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from requests->transformers==4.53.2->-r ./requirements.txt (line 2)) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from jinja2->torch==2.6.0+cu124->-r ./requirements.txt (line 1)) (2.1.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0->-r ./requirements.txt (line 3)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0->-r ./requirements.txt (line 3)) (1.4.0)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0->-r ./requirements.txt (line 3)) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0->-r ./requirements.txt (line 3)) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0->-r ./requirements.txt (line 3)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0->-r ./requirements.txt (line 3)) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0->-r ./requirements.txt (line 3)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\kimyo\\anaconda3\\envs\\test\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0->-r ./requirements.txt (line 3)) (1.20.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r ./requirements.txt \\\n",
        "  --extra-index-url https://download.pytorch.org/whl/cu124"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQuXytZ8FgL1",
        "outputId": "e9742c3a-e0ac-4ab0-a123-aee398b12d4f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np, re, warnings\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIuKAxCxekOM"
      },
      "source": [
        "2. 경로 & 모델/폴드 수 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cOm4LdNUFgOP"
      },
      "outputs": [],
      "source": [
        "input_dir   = \"./ensemble/data/val_ensemble_folding/\"\n",
        "output_path = \"./ensemble/data/meta_train.csv\"\n",
        "\n",
        "models   = ['gemma', 'qwen', 'xone', 'kanana']\n",
        "n_folds  = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34auk1z5fAr2"
      },
      "source": [
        "3. 각 모델별로 fold 예측 누적"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0RGU2u5FgTJ",
        "outputId": "bdc1c60a-ea23-4160-8473-9c5c33b404a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "모든 모델의 fold 예측 누적 완료\n"
          ]
        }
      ],
      "source": [
        "model_full_dfs = {}\n",
        "\n",
        "for m in models:\n",
        "    fold_frames = []\n",
        "\n",
        "    for fold in range(n_folds):\n",
        "        fp = os.path.join(input_dir, f\"val_{m}_fold{fold}.csv\")\n",
        "        if not os.path.isfile(fp):\n",
        "            raise FileNotFoundError(fp)\n",
        "\n",
        "        df = pd.read_csv(fp)\n",
        "\n",
        "        # 필수 컬럼 확인\n",
        "        if not {'ID', 'generated', 'label'}.issubset(df.columns):\n",
        "            raise ValueError(f\"[{fp}] 'ID', 'generated', 'label' 컬럼 필요\")\n",
        "\n",
        "        fold_frames.append(df[['ID', 'generated', 'label']])\n",
        "\n",
        "    # 1. 4개 fold를 세로 방향으로 합치기\n",
        "    full_df = pd.concat(fold_frames, ignore_index=True)\n",
        "\n",
        "    # 2. ID 중복이 있으면 오류 (한 샘플당 예측 1개만 존재해야 함)\n",
        "    if full_df['ID'].duplicated().any():\n",
        "        dup_ids = full_df.loc[full_df['ID'].duplicated(), 'ID'].unique()[:5]\n",
        "        raise ValueError(f\"[{m}] 중복 ID 존재 예: {dup_ids}\")\n",
        "\n",
        "    # 3. ID 기준 정렬\n",
        "    full_df.sort_values('ID', inplace=True)\n",
        "    full_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # 4. 컬럼 이름 변경: generated -> {model}_pred\n",
        "    full_df.rename(columns={'generated': f\"{m}_pred\"}, inplace=True)\n",
        "\n",
        "    model_full_dfs[m] = full_df\n",
        "\n",
        "print(\"모든 모델의 fold 예측 누적 완료\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y9Vk-tkfIGp"
      },
      "source": [
        "4.  모델별 DF를 ID 기준으로 inner-merge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2dQS8s3xFgVp"
      },
      "outputs": [],
      "source": [
        "meta_df = model_full_dfs[models[0]].copy()\n",
        "\n",
        "for m in models[1:]:\n",
        "    meta_df = meta_df.merge(\n",
        "        model_full_dfs[m][['ID', f\"{m}_pred\", 'label']],\n",
        "        on='ID',\n",
        "        how='inner',\n",
        "        suffixes=('', '_tmp')\n",
        "    )\n",
        "    # label 일관성 확인\n",
        "    if not (meta_df['label'] == meta_df['label_tmp']).all():\n",
        "        raise ValueError(f\"Label 불일치 발생 – 모델 {m}\")\n",
        "    meta_df.drop(columns=['label_tmp'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htChH4kwfdAq"
      },
      "source": [
        "5. 최종 정렬 & 컬럼 순서 지정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ihpID9qHFgX9"
      },
      "outputs": [],
      "source": [
        "meta_df.sort_values('ID', inplace=True)\n",
        "meta_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "pred_cols = [f\"{m}_pred\" for m in models]\n",
        "meta_df   = meta_df[['ID'] + pred_cols + ['label']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mECFslSwfjPV"
      },
      "source": [
        "6. 점검 & 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxiiD68AFgZz",
        "outputId": "b35e0f05-ca60-4270-8c53-1407eea05e88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " meta_train.csv 저장 완료 : ./ensemble/data/meta_train.csv\n",
            "shape = (121524, 6)  (행 121524, 열 6)\n",
            "\n",
            " <preview>\n",
            "            ID  gemma_pred  qwen_pred  xone_pred  kanana_pred  label\n",
            "0  FOLD0_00000    1.000000   1.000000   1.000000     1.000000      1\n",
            "1  FOLD0_00001    0.287109   0.235352   0.283203     0.320312      0\n",
            "2  FOLD0_00002    1.000000   1.000000   1.000000     1.000000      1\n",
            "3  FOLD0_00003    0.285156   0.417969   0.289062     0.312500      1\n",
            "4  FOLD0_00004    0.314453   0.337891   0.296875     0.253906      0\n"
          ]
        }
      ],
      "source": [
        "assert meta_df.isna().sum().sum() == 0, \"NaN 값 존재\"\n",
        "\n",
        "meta_df.to_csv(output_path, index=False)\n",
        "print(f\"\\n meta_train.csv 저장 완료 : {output_path}\")\n",
        "print(f\"shape = {meta_df.shape}  (행 {len(meta_df)}, 열 {len(meta_df.columns)})\")\n",
        "print(\"\\n <preview>\")\n",
        "print(meta_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii9ARvbsPAh7"
      },
      "source": [
        "**meta_test.csv 생성**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxNiWtQCf0Dy"
      },
      "source": [
        "1. 경로 & 모델 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nrutI7P7msod"
      },
      "outputs": [],
      "source": [
        "input_dir = './ensemble/data/test_ensemble_folding/'\n",
        "\n",
        "output_path = './ensemble/data/meta_test.csv'\n",
        "\n",
        "# 사용 중인 base model 이름 리스트\n",
        "base_models = ['gemma', 'qwen', 'xone', 'kanana']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX8Ji5Cbf7Dq"
      },
      "source": [
        "2. 각 base model들의 원본 test.csv 추론값을 기반으로 meta_test.csv 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXjxT8RxmsqX",
        "outputId": "9c5dfd26-f18e-494c-dc88-646a13cf2609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "meta_test.csv 파일이 저장되었습니다: ./ensemble/data/meta_test.csv\n"
          ]
        }
      ],
      "source": [
        "# 입력 디렉토리 확인\n",
        "if not os.path.exists(input_dir):\n",
        "    raise ValueError(f\"입력 디렉토리가 존재하지 않습니다: {input_dir}\")\n",
        "\n",
        "try:\n",
        "    # 모든 base model에 대해 폴드 예측 결과 불러와 평균 계산\n",
        "    mean_predictions = {}\n",
        "    ids = None  # 첫 번째 모델의 fold0 파일 ID를 기준으로 사용\n",
        "\n",
        "    for model in base_models:\n",
        "        # 각 모델의 4개 fold 예측 파일 읽기\n",
        "        fold_preds = []\n",
        "        for fold in range(4):\n",
        "            file_name = f\"test_{model}_fold{fold}.csv\"\n",
        "            file_path = os.path.join(input_dir, file_name)\n",
        "            if not os.path.isfile(file_path):\n",
        "                raise FileNotFoundError(f\"예측 결과 파일을 찾을 수 없습니다: {file_path}\")\n",
        "\n",
        "            df = pd.read_csv(file_path)\n",
        "\n",
        "            # 필요한 컬럼 존재 확인\n",
        "            if 'ID' not in df.columns or 'generated' not in df.columns:\n",
        "                raise ValueError(f\"파일에 'ID' 또는 'generated' 컬럼이 없습니다: {file_path}\")\n",
        "\n",
        "            # ID 열 일치 확인 (모든 파일의 ID 순서가 동일해야 함)\n",
        "            if ids is None:\n",
        "                ids = df['ID']\n",
        "            else:\n",
        "                if not ids.equals(df['ID']):\n",
        "                    raise ValueError(f\"{model} 모델의 fold{fold} 예측 파일의 ID 순서가 일치하지 않습니다: {file_path}\")\n",
        "\n",
        "            fold_preds.append(df['generated'])\n",
        "\n",
        "        # 4개 fold의 예측값 평균 계산\n",
        "        preds_concat = pd.concat(fold_preds, axis=1)\n",
        "        mean_pred = preds_concat.mean(axis=1)\n",
        "        mean_predictions[model] = mean_pred.values\n",
        "\n",
        "    # 메타 테스트 데이터프레임 생성\n",
        "    meta_df = pd.DataFrame({'ID': ids})\n",
        "    for model in base_models:\n",
        "        col_name = f\"pred_mean_{model}\"\n",
        "        meta_df[col_name] = mean_predictions[model]\n",
        "\n",
        "    # 결과를 CSV로 저장\n",
        "    meta_df.to_csv(output_path, index=False)\n",
        "    print(f\"meta_test.csv 파일이 저장되었습니다: {output_path}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"오류 발생: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiRpafo_gF8J"
      },
      "source": [
        "3. meta_test.csv 파일 구조 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00SGcAoomTfn",
        "outputId": "d7110f26-07ff-4d8c-a853-a160a71b5188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Top5 rows of meta_test:\n",
            "          ID  pred_mean_gemma  pred_mean_qwen  pred_mean_xone  \\\n",
            "0  TEST_0000         0.379236        0.924513        0.465177   \n",
            "1  TEST_0001         0.393475        0.963943        0.994570   \n",
            "2  TEST_0002         0.237335        0.258387        0.283300   \n",
            "3  TEST_0003         0.814698        0.871969        0.985487   \n",
            "4  TEST_0004         0.904595        0.947946        0.952819   \n",
            "\n",
            "   pred_mean_kanana  \n",
            "0          0.273906  \n",
            "1          0.976941  \n",
            "2          0.213849  \n",
            "3          0.977091  \n",
            "4          0.810718  \n"
          ]
        }
      ],
      "source": [
        "print(\"\\n Top5 rows of meta_test:\")\n",
        "print(meta_df.head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXG1KrH0PG_9"
      },
      "source": [
        "**meta model 훈련 및 추론**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nLF9JfGgMs4"
      },
      "source": [
        "1. 경로 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FvX6kMyF1p7f"
      },
      "outputs": [],
      "source": [
        "meta_train_path = './ensemble/data/meta_train.csv'\n",
        "meta_test_path  = './ensemble/data/meta_test.csv'\n",
        "submission_path = './final_submission.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hwhMrhAgTV4"
      },
      "source": [
        "3. meta_train / meta_test 로드 & 검증 및 logit feature 추가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Gu8CAGhn1qAp"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(meta_train_path)\n",
        "test  = pd.read_csv(meta_test_path)\n",
        "\n",
        "assert train['ID'].is_unique and test['ID'].is_unique, \"ID 중복\"\n",
        "assert not train.isna().any().any() and not test.isna().any().any(), \"NaN 존재\"\n",
        "\n",
        "# test 컬럼명  pred_mean_modelX -> modelX_pred\n",
        "test = test.rename(columns={c: f\"{m.group(1)}_pred\"\n",
        "                            for c in test.columns\n",
        "                            if (m := re.match(r'^pred_mean_(.+)$', c))})\n",
        "\n",
        "base_cols = [c for c in train.columns if c not in ('ID', 'label')]\n",
        "\n",
        "# logit 변환\n",
        "eps = 1e-6\n",
        "for col in base_cols:\n",
        "    train[f\"{col}_logit\"] = np.log((train[col]+eps)/(1-train[col]+eps))\n",
        "    test[f\"{col}_logit\"]  = np.log((test[col] +eps)/(1-test[col] +eps))\n",
        "\n",
        "feature_cols = base_cols + [f\"{c}_logit\" for c in base_cols]\n",
        "\n",
        "X_train = train[feature_cols]\n",
        "y_train = train['label'].astype(float)\n",
        "X_test  = test[feature_cols].copy()\n",
        "\n",
        "assert list(X_test.columns) == feature_cols, \"feature 순서/누락\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ESivzzqhnGC"
      },
      "source": [
        "4. (Meta Model) Logistic Regression Cross Validation / LR 학습 및 추론 진행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0a5WIBr1qDm",
        "outputId": "9d37abf6-a193-4d29-ae3c-b9e60bc4aa0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "seed 42  ▸ Best C : 0.02304092976055847\n",
            "          OOF AUC = 0.770861\n",
            "seed 56  ▸ Best C : 0.2585234839562191\n",
            "          OOF AUC = 0.770867\n",
            "seed 77  ▸ Best C : 0.14125375446227553\n",
            "          OOF AUC = 0.770866\n",
            "seed 88  ▸ Best C : 2.900681198693156\n",
            "          OOF AUC = 0.770878\n",
            "seed 99  ▸ Best C : 0.042169650342858224\n",
            "          OOF AUC = 0.770861\n",
            "\n",
            " OOF AUC (seed ensemble) : 0.770866689525477\n"
          ]
        }
      ],
      "source": [
        "SEEDS   = [42, 56, 77, 88, 99]\n",
        "C_grid  = np.logspace(-4, 2.3, 25)\n",
        "\n",
        "oof_list, test_list = [], []\n",
        "\n",
        "for seed in SEEDS:\n",
        "    pipe = LogisticRegressionCV(\n",
        "        Cs=C_grid,\n",
        "        cv=StratifiedKFold(n_splits=7, shuffle=True, random_state=seed),\n",
        "        solver='lbfgs',\n",
        "        scoring='roc_auc',\n",
        "        class_weight='balanced',\n",
        "        max_iter=4000,\n",
        "        n_jobs=-1,\n",
        "        random_state=seed\n",
        "    )\n",
        "\n",
        "    pipe.fit(X_train, y_train)\n",
        "    print(f\"seed {seed:<3d} ▸ Best C :\", pipe.C_[0])\n",
        "\n",
        "    oof_pred  = pipe.predict_proba(X_train)[:, 1]\n",
        "    auc       = roc_auc_score(y_train, oof_pred)\n",
        "    print(f\"          OOF AUC = {auc:.6f}\")\n",
        "\n",
        "    oof_list.append(oof_pred)\n",
        "    test_list.append(pipe.predict_proba(X_test)[:, 1])\n",
        "\n",
        "# 평균 앙상블\n",
        "oof_avg  = np.mean(oof_list,  axis=0)\n",
        "pred_avg = np.mean(test_list, axis=0)\n",
        "print(\"\\n OOF AUC (seed ensemble) :\", roc_auc_score(y_train, oof_avg))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrLZSizpiBxS"
      },
      "source": [
        "5. 최종 제출 파일 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CFykz1u1qF0",
        "outputId": "e6bff371-1394-43b5-e83f-f2817929be97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Saved submission → ./final_submission.csv\n",
            "          ID  generated\n",
            "0  TEST_0000   0.510497\n",
            "1  TEST_0001   0.925113\n",
            "2  TEST_0002   0.263866\n",
            "3  TEST_0003   0.925431\n",
            "4  TEST_0004   0.886927\n"
          ]
        }
      ],
      "source": [
        "submission = pd.DataFrame({'ID': test['ID'], 'generated': pred_avg})\n",
        "submission.to_csv(submission_path, index=False)\n",
        "print(f\"\\n Saved submission → {submission_path}\")\n",
        "print(submission.head())\n",
        "\n",
        "assert submission.shape[1] == 2, \"컬럼이 일치하지 않습니다.\"\n",
        "assert submission['generated'].isna().sum() == 0, \"NaN 존재\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV-2C5GjiPuO"
      },
      "source": [
        "6. 제출 파일 검증 (행 수 확인)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZqYg4ds1qIT",
        "outputId": "bd0ae98e-cd7e-4b2d-c5d7-e2e770163854"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "행 수 일치: meta_test.csv와 final_submission.csv = 1962\n"
          ]
        }
      ],
      "source": [
        "if len(test) == len(submission):\n",
        "    print(f\"행 수 일치: meta_test.csv와 final_submission.csv = {len(test)}\")\n",
        "else:\n",
        "    print(f\"행 수 불일치: meta_test.csv = {len(test)},  final_submission = {len(submission)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
